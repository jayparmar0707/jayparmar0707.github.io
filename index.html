<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Jay Parmar | Portfolio</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet"/>
  <style>
    body {
      margin: 0;
      font-family: 'Roboto', sans-serif;
      background-color: #f2f2f2;
      color: #333;
    }

    .container {
      max-width: 900px;
      margin: 3rem auto;
      padding: 2rem;
      background-color: #fff;
      border-radius: 12px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      text-align: center;
    }

    img {
      width: 180px;
      height: 180px;
      border-radius: 50%;
      object-fit: cover;
      border: 3px solid #1b1b1b;
      margin-bottom: 1.2rem;
    }

    h1 {
      font-size: 2.5rem;
      margin: 0.5rem 0;
    }

    p {
      font-size: 1.1rem;
      margin: 1rem 0 2rem;
    }

    .links a {
      display: inline-block;
      margin: 0.5rem 1rem;
      padding: 0.6rem 1.2rem;
      border-radius: 8px;
      text-decoration: none;
      font-weight: bold;
      background-color: #1b1b1b;
      color: #fff;
      transition: background 0.3s;
    }

    .links a:hover {
      background-color: #333;
    }

    @media (max-width: 600px) {
      h1 {
        font-size: 2rem;
      }

      .links a {
        display: block;
        margin: 0.5rem auto;
        width: 80%;
      }
    }
  </style>
</head>
<body>

  <div class="container">
    <img src="images/profile.jpg" alt="Jay Parmar" />

    <h1>Jay Parmar</h1>
    <p>PhD Student in Computer Science @ UCF<br>
       Multimodal AI & Video Understanding</p>

    <div class="summary">
      <p>Iâ€™m a Computer Science PhD student at the University of Central Florida working in the Center for Research in Computer Vision (CRCV). My research centers on <strong>vision-language models (VLMs)</strong>, <strong>video understanding</strong>, and <strong>fine-grained retrieval</strong>, with a special focus on addressing <strong>privacy preservation and bias mitigation</strong>.</p>

      <p>I've co-developed a benchmark dataset for Composed Video Retrieval (CoVR), and contributed methods that outperform prior models on tasks like action recognition and video-text alignment. My recent work includes anonymization-aware VLMs for pedestrian and traffic footage, and large-scale YouTube data collection for safety systems.</p>

      <p>Previously, I conducted machine learning research on solar panel diagnostics using IV curve classification and image-based fault detection. I also led and mentored undergrad students in CS fundamentals as a Supplemental Instruction Leader, receiving recognition for my teaching support.</p>

      <p>I enjoy building responsible, scalable AI that serves real-world needs, with open-source contributions and public benchmarks as a key part of my philosophy.</p>
    </div>

    <div class="publications">
        <h3>Publications</h3>
        <ul>
        <li>
            Gupta, Animesh, Jay Parmar, Ishan Rajendrakumar Dave, and Mubarak Shah. 
            <em>From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos</em>. 
            arXiv preprint arXiv:2506.05274, 2025. Under review at NeurIPS 2025. 
            <a href="https://arxiv.org/abs/2506.05274" target="_blank">https://arxiv.org/abs/2506.05274</a>
        </li>
        </ul>
    </div>

    <div class="links">
      <a href="https://github.com/jayparmar0707" target="_blank">GitHub</a>
      <a href="https://www.linkedin.com/in/jay-parmar-094572340/" target="_blank">LinkedIn</a>
      <a href="Resume.pdf" target="_blank">Resume</a>
    </div>
  </div>

</body>
</html>
